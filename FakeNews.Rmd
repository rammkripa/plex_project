---
title: 'Faux & Friends: A Fake News Detection and Analysis Service'
author: "Allen Chen, Ram Mukund Kripa"
date: "8/4/2020"
output: html_document
runtime: shiny
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

### Packages used in this Project

```{r packages}
library(tidyverse)
library(hoaxy)
library(rtweet)
library(tidytext)
library(here)
library(shiny)
```

# Fake News

### Creating the Dataset

```{r}
print("Hello")
```


## Interactive Environment

## Please Enter a Twitter Handle

```{r input_handle, echo=FALSE}
inputPanel(
  textInput("input_name", label = "Twitter Username",
              value = "realDonaldTrump")
)

```

## Analysis

### Most Common Words in Recent Tweets

```{r plot}
renderPlot({
 
  user_dat <- get_timeline(user = input$input_name,
                           n = 3200
                           )
  user_clean <- user_dat %>%
    mutate(text = sub("http.*", "", text) ) %>%
    unnest_tokens(output = "tweet_words",
                  input = text,
                  token = "words") %>%
    select(screen_name,created_at,tweet_words) %>%
    anti_join(stop_words, by = c("tweet_words" = "word")) %>%
    filter(tweet_words!="amp")
    #%>%
    #mutate(tweet_words = SnowballC::wordStem(tweet_words))
  
  user_clean %>%
    group_by(tweet_words) %>%
    summarize(count = n()) %>%
    arrange(-count) %>%
    head(n = 6L) %>%
    ggplot(mapping = aes(x = reorder(tweet_words,count),
                         y = count))+
      geom_col()+
      coord_flip()+
      labs(title = glue::glue("Most Common Words for ",input$input_name),
           x = "Word Stem",
           y = "Number of Occurences")
  
})
```